# LLM with `EC2`

https://medium.com/@chinmayd49/self-host-llm-with-ec2-vllm-langchain-fastapi-llm-cache-and-huggingface-model-7a2efa2dcdab

This article deals with self hosting an Huggingface LLM using EC2 Instaces
<!--stackedit_data:
eyJoaXN0b3J5IjpbNTE4NTE2NjYxXX0=
-->